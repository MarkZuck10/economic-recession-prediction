{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkZuck10/economic-recession-prediction/blob/main/BERTweet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. preparing dataset"
      ],
      "metadata": {
        "id": "W_Ta23zGhhL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJLF1_Rac6B2",
        "outputId": "25b98215-f167-4ad0-ce6e-de1c0d09ab78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21954, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/2023_02_01_rawtext.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "tSul6lTgfgK6",
        "outputId": "0d7a24ab-9c5d-4f55-c12c-daaf7ea9aca1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       0\n",
              "tweetid    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweetid</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df.isna().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjuftdCVhpFb",
        "outputId": "4b4ac0e4-fa3f-40eb-d7ec-3dde61c063bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. batch processed pretrained BERTweet"
      ],
      "metadata": {
        "id": "fETEQCt_xxy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "!pip install emoji==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm10VHTBvXlb",
        "outputId": "4c71f0f8-509b-4465-b7c8-5e179b93f4d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the pre-trained BERTweet sentiment analysis model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBFNRD7ELB-F",
        "outputId": "d8ddce1e-9f8f-40a5-8a30-7a458f1f4f44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweets(tweets):\n",
        "    return tokenizer(tweets, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "batch_size = 256\n",
        "sentiment_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "predicted_sentiments = []"
      ],
      "metadata": {
        "id": "4TV8fGj6vXi5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(df), batch_size):\n",
        "    batch_tweets = df['text'][i:i+batch_size].tolist()\n",
        "    encoded_tweets = preprocess_tweets(batch_tweets)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_tweets)\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    batch_predicted_sentiments = [sentiment_labels[label.item()] for label in predictions]\n",
        "    predicted_sentiments.extend(batch_predicted_sentiments)"
      ],
      "metadata": {
        "id": "Sjeu_XUeyDo6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bertweet_sentiment'] = predicted_sentiments"
      ],
      "metadata": {
        "id": "w0f1naPfyDli"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Saving dataset"
      ],
      "metadata": {
        "id": "4Eu888x24CV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_counts = df['bertweet_sentiment'].value_counts()\n",
        "print(sentiment_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoUOFrH8yDkO",
        "outputId": "9bd0f373-3e4d-49dd-a109-30a03977d69f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bertweet_sentiment\n",
            "Neutral     10165\n",
            "Negative     8739\n",
            "Positive     3050\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/My Drive/01-02-23_BERTweet-sentiment.csv', index=False)"
      ],
      "metadata": {
        "id": "-C3lg6fZ4EnV"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1O--CLZwQgXWkm3R9h6QtpuPZU0ie7ysD",
      "authorship_tag": "ABX9TyMC02K8MZ/VtKM55XtfZuSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}